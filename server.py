# server.py ‚Äî Fixed Brand Detection Logic + Date Filter + Cleanup (Hide Old)
import os
import threading
import logging
import datetime
from datetime import timedelta # 7 —Ö–æ–Ω–æ–≥–∏–π–≥ —Ç–æ–æ—Ü–æ—Ö–æ–¥ —Ö—ç—Ä—ç–≥—Ç—ç–π
from flask import Flask, jsonify, render_template, send_from_directory, url_for, request
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger

import run
from db import banners_col

# Setup
app = Flask(__name__, template_folder="templates", static_folder="static")
logging.getLogger('apscheduler').setLevel(logging.WARNING)

# Global State
SCRAPE_LOCK = threading.Lock()
IS_RUNNING = False
LOG_BUFFER = []

# -----------------------------------------------------------
# 1. –ë–†–≠–ù–î –¢–ê–ù–ò–• –õ–û–ì–ò–ö
# -----------------------------------------------------------
BRAND_MAP = {
    # Banks
    "khanbank": "–•–∞–∞–Ω –ë–∞–Ω–∫",
    "golomt": "–ì–æ–ª–æ–º—Ç –ë–∞–Ω–∫",
    "tdbm": "–•–•–ë (TDB)",
    "statebank": "–¢”©—Ä–∏–π–Ω –ë–∞–Ω–∫",
    "capitron": "–ö–∞–ø–∏—Ç—Ä–æ–Ω",
    "bogdbank": "–ë–æ–≥–¥ –ë–∞–Ω–∫",
    "nibs": "“Æ–•–û–ë",
    "transbank": "–¢—ç—ç–≤—ç—Ä –•”©–≥–∂–ª–∏–π–Ω –ë–∞–Ω–∫",
    "qpay": "QPay",
    "monpay": "MonPay",
    "socialpay": "SocialPay",
    "toki": "Toki",
    "storepay": "StorePay",
    "lendmn": "LendMN",
    "koreanair": "Korean-Air",

    # Telco
    "unitel": "Unitel",
    "mobicom": "Mobicom",
    "skytel": "Skytel",
    "gogo": "GoGo",
    "univision": "Univision",
    "gmobile": "G-MOBILE",

    # Shopping & Others
    "shoppy": "Shoppy",
    "uran": "Uran",
    "bsb": "BSB",
    "pc-mall": "PC Mall",
    "next": "Next Electronics",
    "nomin": "Nomin",
    "emart": "Emart",
    "cu-mongolia": "CU",
    "gs25": "GS25",
    "tavanbogd": "Tavan Bogd",
    "mcs": "MCS",
    "apu": "APU",
    "unegui": "Unegui.mn",
    "zangia": "Zangia.mn",
    "ihelp": "iHelp",
    "bet": "Betting/Gambling",
    "1xbet": "1xBet",
    "spoj": "Sport",
    "Freshpack": "Freshpack",
    "Esain": "Sain Electronics",
}

def detect_brand(url: str, src: str) -> str:
    text_to_check = (str(url) + " " + str(src)).lower()
    for key, brand_name in BRAND_MAP.items():
        if key in text_to_check:
            return brand_name
    return None

def ui_logger(message: str):
    timestamp = datetime.datetime.now().strftime("%H:%M:%S")
    entry = f"[{timestamp}] {message}"
    print(entry)
    global LOG_BUFFER
    LOG_BUFFER.append(entry)
    if len(LOG_BUFFER) > 200: LOG_BUFFER.pop(0)

def job_runner(source="Auto"):
    global IS_RUNNING
    if IS_RUNNING:
        ui_logger(f"‚ö† {source}: Scraper is busy.")
        return
    with SCRAPE_LOCK:
        IS_RUNNING = True
        global LOG_BUFFER
        LOG_BUFFER = []
        ui_logger(f"üöÄ {source}: Starting Pipeline...")
        try:
            res = run.run_pipeline()
            if res.get("status") == "failed":
                ui_logger(f"‚ùå Failed: {res.get('error')}")
            else:
                stats = res.get("stats", {})
                ui_logger(f"‚úÖ Done. Total: {stats.get('total_collected')}, New: {stats.get('new_banners')}")
        except Exception as e:
            ui_logger(f"‚ùå Error: {e}")
        finally:
            IS_RUNNING = False

if os.environ.get("WERKZEUG_RUN_MAIN") == "true":
    try:
        scheduler = BackgroundScheduler()
        scheduler.add_job(job_runner, CronTrigger(hour=9, minute=0, timezone='Asia/Ulaanbaatar'), id='daily')
        scheduler.start()
        print("‚úÖ Scheduler started.")
    except: pass

# --- ROUTES ---

@app.route("/")
def index():
    # 1. Filter Parameters
    start_date = request.args.get('start', '')
    end_date = request.args.get('end', '')
    
    # “Æ–Ω–¥—Å—ç–Ω query: –ù—É—É–≥–¥—Å–∞–Ω (hidden=True) –∑–∞—Ä—É—É–¥—ã–≥ —Ö–∞—Ä—É—É–ª–∞—Ö–≥“Ø–π
    query = {"hidden": {"$ne": True}}

    # 2. Date Filter Logic
    if start_date or end_date:
        date_filter = {}
        if start_date:
            date_filter["$gte"] = start_date
        if end_date:
            date_filter["$lte"] = end_date
        
        if date_filter:
            # first_seen_date-—ç—ç—Ä —à“Ø“Ø—Ö (—Ö—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω —Ö“Ø—Å—ç–ª—Ç—ç—ç—Ä)
            query["first_seen_date"] = date_filter

    # 3. Data Fetch
    rows = []
    if banners_col is not None:
        rows = list(banners_col.find(query, {"_id": 0}).sort("last_seen_date", -1))
    
    # 4. Process Rows (Status & Brand)
    today_str = datetime.datetime.now().strftime("%Y-%m-%d")
    processed_rows = []

    for r in rows:
        # STATUS
        last_seen = r.get("last_seen_date", "")
        if last_seen == today_str:
            r['status'] = 'üü¢ –ò–î–≠–í–•–¢–≠–ô'
        else:
            r['status'] = '‚ö™ –î–£–£–°–°–ê–ù'

        # SCREENSHOT URL
        path = r.get("screenshot_path")
        if path and os.path.exists(path):
            filename = os.path.basename(path)
            r['screenshot_file'] = url_for('serve_banner_image', filename=filename)
        else:
            r['screenshot_file'] = None

        # BRAND DETECTION
        landing = r.get('landing_url', '')
        src = r.get('src', '')
        detected = detect_brand(landing, src)
        if detected:
            r['brand'] = detected
        else:
            r['brand'] = r.get('site', '–ë—É—Å–∞–¥')

        processed_rows.append(r)

    # Check Files for Download
    export_dir = os.path.join(os.path.dirname(__file__), "_export")
    xlsx_exists = os.path.exists(os.path.join(export_dir, "summary.xlsx"))
    tsv_exists = os.path.exists(os.path.join(export_dir, "summary.tsv"))

    return render_template(
        "scraper.html", 
        rows=processed_rows, 
        xlsx_exists=xlsx_exists, 
        tsv_exists=tsv_exists,
        start_date=start_date, 
        end_date=end_date
    )

# --- NEW: CLEANUP ROUTE (7+ —Ö–æ–Ω–æ–≥–∏–π–Ω ”©–º–Ω”©—Ö –∑–∞—Ä—ã–≥ –Ω—É—É—Ö) ---
@app.route("/scraper/cleanup", methods=["POST"])
def cleanup_old_ads():
    """
    –°“Ø“Ø–ª–∏–π–Ω 7 —Ö–æ–Ω–æ–≥—Ç —Ö–∞—Ä–∞–≥–¥–∞–∞–≥“Ø–π (last_seen_date < 7 days ago) –∑–∞—Ä—É—É–¥—ã–≥
    hidden=True –±–æ–ª–≥–æ–∂ –∂–∞–≥—Å–∞–∞–ª—Ç–∞–∞—Å –Ω—É—É–Ω–∞ (Soft Delete).
    """
    if banners_col is None:
        return jsonify({"error": "No DB connection"}), 500

    try:
        # 7 —Ö–æ–Ω–æ–≥–∏–π–Ω ”©–º–Ω”©—Ö –æ–≥–Ω–æ–æ–≥ –æ–ª–æ—Ö
        cutoff_date = datetime.datetime.now() - timedelta(days=7)
        cutoff_str = cutoff_date.strftime("%Y-%m-%d")

        # Query: 7 —Ö–æ–Ω–æ–≥–æ–æ—Å ”©–º–Ω”© —Ö–∞—Ä–∞–≥–¥—Å–∞–Ω –ë”®–ì”®”®–î –æ–¥–æ–æ–≥–æ–æ—Ä –Ω—É—É–≥–¥–∞–∞–≥“Ø–π –±–∞–π–≥–∞–∞ –∑–∞—Ä—É—É–¥
        filter_query = {
            "last_seen_date": {"$lt": cutoff_str},
            "hidden": {"$ne": True}
        }

        # Update: hidden = True –±–æ–ª–≥–æ—Ö
        result = banners_col.update_many(filter_query, {"$set": {"hidden": True}})
        
        msg = f"Archived {result.modified_count} old banners (older than {cutoff_str})."
        ui_logger(msg)
        
        return jsonify({"status": "success", "archived": result.modified_count})

    except Exception as e:
        ui_logger(f"Cleanup Error: {e}")
        return jsonify({"error": str(e)}), 500

# --- NEW: DELETE ROUTE (–ì–∞–Ω—Ü –∑–∞—Ä—ã–≥ –±“Ø—Ä –º”©—Å”©–Ω —É—Å—Ç–≥–∞—Ö) ---
@app.route("/api/delete_banner", methods=["POST"])
def delete_banner():
    """
    –¢–æ–≤—á–ª—É—É—Ä –¥–∞—Ä–∞—Ö–∞–¥ —Ç—É—Ö–∞–π–Ω –∑–∞—Ä—ã–≥ DB-—ç—ç—Å —É—Å—Ç–≥–∞—Ö.
    """
    if banners_col is None:
        return jsonify({"error": "No DB connection"}), 500
    
    try:
        data = request.json
        src = data.get("src")
        site = data.get("site")
        
        if not src or not site:
            return jsonify({"error": "Missing src or site"}), 400
            
        # DB-—ç—ç—Å —É—Å—Ç–≥–∞—Ö (Hard Delete)
        res = banners_col.delete_one({"src": src, "site": site})
        
        if res.deleted_count > 0:
            return jsonify({"status": "success"})
        else:
            return jsonify({"error": "Not found"}), 404
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# --- NEW: ARCHIVE ONE (–ì–∞–Ω—Ü –∑–∞—Ä—ã–≥ –∂–∞–≥—Å–∞–∞–ª—Ç–∞–∞—Å –Ω—É—É—Ö - Optional) ---
# –•—ç—Ä—ç–≤ —Ç–∞ "–£—Å—Ç–≥–∞—Ö" —Ç–æ–≤—á–æ–æ—Ä –±“Ø—Ä –º”©—Å”©–Ω –±–∏—à, –∑“Ø–≥—ç—ç—Ä –Ω—É—É—Ö—ã–≥ —Ö“Ø—Å–≤—ç–ª “Ø“Ø–Ω–∏–π–≥ –∞—à–∏–≥–ª–∞–∂ –±–æ–ª–Ω–æ.
@app.route("/scraper/archive-one", methods=["POST"])
def archive_one_banner():
    if banners_col is None: return jsonify({"error": "No DB"}), 500
    try:
        data = request.json
        banners_col.update_one(
            {"src": data.get("src"), "site": data.get("site")},
            {"$set": {"hidden": True}}
        )
        return jsonify({"status": "success"})
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route("/banners/<path:filename>")
def serve_banner_image(filename):
    return send_from_directory("banner_screenshots", filename)

@app.route("/download/xlsx")
def download_xlsx():
    export_dir = os.path.join(os.path.dirname(__file__), "_export")
    return send_from_directory(export_dir, "summary.xlsx", as_attachment=True)

@app.route("/download/tsv")
def download_tsv():
    export_dir = os.path.join(os.path.dirname(__file__), "_export")
    return send_from_directory(export_dir, "summary.tsv", as_attachment=True)

@app.route("/scraper/scrape-now", methods=["POST"])
def scrape_now():
    global IS_RUNNING
    if IS_RUNNING: return jsonify({"status": "busy"})
    threading.Thread(target=job_runner, args=["Manual"]).start()
    return jsonify({"status": "started"})

@app.route("/scraper/status")
def status():
    return jsonify({"running": IS_RUNNING})

@app.route("/_debug/last-log")
def last_log():
    return "\n".join(LOG_BUFFER)

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8899, debug=True)